# Documentation

- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Example](#example)

## Introduction

A plugin for the survey platform LimeSurvey that allows participants' answers to be dynamically inserted into a prompt for a Large Language Model (LLM) and displays the generated output directly in the survey for evaluation. This project was developed as part of a thesis to simplify empirical research on the quality of personalized LLM output.

### Why this plugin?

The quality of LLM-generated texts is highly context-dependent and often requires human evaluation. Previously, the empirical collection of feedback for personalized LLM output was very cumbersome: researchers had to collect data in an initial survey, manually generate the output, and present it for evaluation in a second, separate survey. This process is slow, error-prone, and interrupts the study flow.

This plugin solves the problem by automating the entire process and integrating it into a single survey run. It closes the gap between data collection, the dynamic generation of personalized LLM output, and its immediate evaluation by participants â€” all within the same survey.

### Core Features

The plugin extends LimeSurvey with the capability to use participant answers (e.g., [age]) directly as placeholders in a prompt. The resulting text generated by the LLM can be automatically displayed within predefined elements on a subsequent page of the survey, where it can be immediately evaluated by the participants. The configuration, the prompts used, and the generated output are saved along with the survey data to ensure complete traceability.

## Installation

1. Create a new folder inside your LimeSurvey plugins folder with the name `LLMSurvey`.

   ```
   mkdir /LIMESURVEY_HOME_FOLDER/plugins/LLMSurvey
   ```

2. Paste all files from the `src/` folder into the created folder.

## Usage

### Getting Started

1. Find LLMSurvey in the plugins tab of your LimeSurvey page.

2. Activate the plugin.

3. Add your OpenRouter access key in the settings tab of the plugin.

4. Add one or multiple LLMs to the global plugin settings. See [Adding a New LLM](#adding-a-new-llm)

### Creating an example survey

1. Create your survey normally but try to use meaningful question codes for the questions and subquestions you wish to use in the prompt later. You will need them to insert the users answers into the prompt. See [Prompts](#prompts)

2. Create a new question group at the end of your survey with the questions into which the LLM output should then be inserted. It is important that these placeholder questions are placed on later pages than the last question whose answer you want to include in the prompt. Assigning the LLM output to the placeholder questions works via the questions code as well. See [Displaying LLM Output](#displaying-llm-output)

   - Right before the first page containing placeholder questions is loaded, the LLM request is performed. This normally takes a few seconds. You may consider adding another question group with a text notice to inform your participants of data processing and loading times.

3. Make sure you've set everything in the plugins survey settings for your survey. Note that `Temperature`, `Max Tokens` and `Top P` can be left empty to use the models defaults.

4. Please only activate the survey at the very last. Otherwise some important data cannot be exported later. See [Activating a Survey](#activating-a-survey)

### Settings

#### Adding a New LLM

The llm requests are handled by [openrouter](https://openrouter.ai/). To add a new model to the list of available models, head to the [models page](https://openrouter.ai/models) and copy the models' code:<br>
![openrouter model code example](images/openrouter-model-code.png)

Paste the code in the `Large Language Models` field in the global plugin settings. Each code needs to have its own line with no other characters:<br>
![plugin language model list](images/plugin-model-list.png)

#### Prompts

To insert a users answers into the prompt use square brackets with the questions code.
For example if you have a question with the code `age` that asks the user for their age, you can include it in the prompt as follows:

```
A user is [age] years old and...
```

becomes

```
A user is 25 years old and...
```

![Prompt example](images/prompt-example.png)

Note that ONLY the answer of a question is inserted and not the questions text. You need the tell the LLM what any answer means.
For **multiple choice** questions a `Yes` is returned for a selected item (not the item itself!). If not selected the answer is empty.
To include data from subquestions or other question types, see [Prompt Codes](prompt-codes.md)

### Displaying LLM Output

Use the code `llm{index}` in a **questionCode**, **subquestionCode** or **answerCode** to insert the LLM output at this index into the questionnaire object.
Start the index at the number 1 to get the first object. (`llm1`)
You can use any text as the questions text since the user will only see the replaced text.
If you declare a placeholder question with an index out of bounds, the plugin will hide the question / subquestion / answer from the user so no empty elements are shown in the survey.

Note: The question type `bootstrap dropdown` cannot be used to display LLM output. Please use normal `list dropdown`.

### Activating a Survey

Activate the survey after making sure, your settings and questions are correctly set.
On activation the plugin inserts a few hidden questions. These are used to save the language model, prompt and parameters within the response.
A hidden question with the code `llmOutput{index}` is inserted right before the first occurrence of each llm-placeholder to store the LLM output at this index.
The survey can be deactivated and activated again however if you've changed the order of an llm-placeholder question, you may want to move the inserted hidden question that stores the output at that index as well. If you delete an automatically added hidden question, it just gets created again when the survey is activated.

Note: Because the plugin will hide questions, subquestions or answers whose index exceeds the returned LLM output, every placeholder question will be set to non-mandatory upon activation because having a mandatory question hidden can result in the survey being incompletable.

## Example

Basic survey structure:<br>
![structure](images/structure.png "Survey structure")<br>
A closer look into the `requirements` question:<br>
![requirements subquestions](images/requirements-subquestions.png "Requirements - subquestions")<br>
The first placeholder question:<br>
![placeholder question](images/placeholder-question.png "Placeholder question")
The plugins survey settings:<br>
![survey settings](images/survey-settings.png)<br>

Now we activate the survey. The structure now looks like this:<br>
![structure after activation](images/structure-after-activation.png "Structure after activating the survey")<br>

We can now run the survey as a test. With the provided example, the generated prompt looks like this:

```
You are a software developer (25 years old with the gender Male). You have 7 years of experience with IDEs.

You already expressed the following requirements for IDEs:
syntax highlighting
intelligent code completions
addons and plugins
debugging tools
refactoring methods
```

The LLM returned:

```json
["Version Control Integration", "Performance Profiling Tools"]
```

Which is then mapped onto the prepared questions:

![LLM requirement 1](images/llm-req1.png)
![LLM requirement 2](images/llm-req2.png)
